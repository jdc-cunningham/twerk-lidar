I did some of my day-job tasks so doing this now.

I want to get past reworking the walking gait.

Then I will start doing the sweep sampling.

I'm still struggling to get this down ha, this forward walking gait.

In the videos I watched they did not "lunge" forward, the forward motion of any legs somehow pulled the robot forward too without some kind of lunging motion.

I've got a stable triangle. I will try:

- front-right leg moves forward
- back-left leg moves up
- legs on the ground "lunge" forward

Then I don't know if it just repeats or will the legs be in the wrong place.

This walking gait is not much better. It also slowly turns to the right.

I think I will add the servo current position tracker thing.

Ideally any future movements would be based on these current/last set positions.

Let me [film this](https://www.youtube.com/watch?v=x5cfE5tZZ5Y)

I also need to lift the legs up more.

Oh I guess I could pull the front legs back more.

Anyway even if the gait sucks I will press on because there are bigger things to deal with than this.

It's getting better but I'm seeing the issue I think. It wants to tip over to some areas like the back-left leg for example.

I will modify that part to pitch the back-right leg down to tilt the nose down.

Hmm... I'm starting to see it. I wanted to call a motion command to stack/add more rotations to the servo but it didn't happen because I was just repeating the fixed start/end rotations.

So instead you could have the global kept servo positions and then just add an amount to it in a direction with max-checks in place.

Nope not a good plan, pretty much I have to not pitch the front legs so far forward.

I think mathematically based on dimensions and how fast the servos move, I can estimate what is its speed... which it would be slow no matter how you look at it since it's not using wheels.

It's also not like a dog-quad where it can hop around/be faster.

Insect design could be fast too but these are not dynamic, I'm not using like actuators that can use electronic breaking to act as a spring.

Yeah I need to move on. Going to check the forward walking gait a bit then check the turning.

This thing chews through power though, like 10s of minutes.

Going to try full speed (0 ms delay)

Lol it doesn't work just jitters... alright will cap to 2ms

That's cool, it looks like an actual forward motion thing.

I will not go this fast though just to reduce wear on the servos. It is still slowly turning right and if something's stuck to the legs (like the blue tape) it well is stuck.

I think I need to fight the right turning by over pulling on the right side.

It's funny now I'm removing the hot glue on the bottom of the feet.

I'm good with the forward walking gait, I can visibly see it progress forward.

I will check the gaits I should at least have full 2D control.

Or at least forward and left.

I will actually have to add the hot glue back since the jagged edges catch on the carpet...

Interesting I now see the 2-pairs on left/right sides walking in series pattern now on my robot.

if you have on a top view:

1  2

3  4

The legs move: 4, 2, 1, 3

Where leg 3 is the farthest back on initial stance, the initial triangle base is 1, 2, 3

I'm glad I bought 4 batteries, I can charge 2 and have 2 to use.

It's really only a problem during development.

The turn left gate needs work unfortuantely. The new stance does not work well with the previous turn left gait.

I want to do something new today though so I will skip that for now.

What is this new thing I want to work on?

The storage of the sampling.

Oh crap... I need to check if the sanning pattern still works with this new base pos.

Seems like it does still work.

So the ToF sensor "API" allows for continuous or timed measurement.

I think it is safer for me to do start/stop... question is how big...

Ehhh system lol, it is called "system"

The current s-pattern is definitely not enough of a sample set.

The main concern is there is something on the ground it can't see and just runs into it like a small stick.

Lol doesn't have enough power. Looks like I'll be using a dynamic sized array to store the pans and then have multiple rows of these, that I know the size eg. the squiggle pattern.

What'll be interesting is knowing the pitch of the robot relative to the horizon so then the sample can determine how far away it is eg. cosine.

I really need to make a web interface to control it since I keep having to program stuff on/off, I could just command it to tilt up/sample, tilt down, sample that kind of thing.

I was thinking something like this:

[
  [angle, distance1, d2, d3, d4, ...],
  [angle, d1, d2, d3, d4, ...],
]

Oh except you don't have the horizontal angle

Hmm it could be averaged concern is the samples won't be like a square it'll be a squiggle

or no actuall it will be a droplet shape with the widest part at the floor.

ehh... might as well just scan it full size

I still have not done much with the IMU regarding calibration/making sure the values I get from the rotation are matching the real world if I use a protractor... which I think I bought one recently... it's somewhere.

Well that's great I don't know where it is.

Well... worst case I can just print one ha.

Well I'm spent already... but started thinking about next steps.