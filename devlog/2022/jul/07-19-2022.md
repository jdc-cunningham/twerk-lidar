6:05 PM
I want to get that mesh mapping to work from the robot straight to the web.

I'm currently making sure the pan/tilt motion is good. Right now it's doing something weird with one of the legs, it actually ends up crab walking over time which I will need at some point.

Dang one servo died

I'm not going to get it perfect, I'm going to move on.

Ugh... spent so much time messing around, it's still bad.

I'm going to move on. I need to do the external measurements for the new angles and offsets.

Then try to transmit the data to the web interface, from there I should be able to plot the meshes (both) to compare.

this is nasty but a real thing to factor

* tilt up 2
  * sweep
    * left  14.0
    * right 21.7
  * pitch
    * 18.5
* tilt up 1
  * sweep
    * left  12.8
    * right 20.9
  * pitch
    * 11.4
* middle
  * sweep
    * left  13.2
    * right 20.9
  * pitch
    * 1.6
* tilt down 1
  * sweep
    * left  14.2
    * right 16.7
  * pitch
    * 8.8
* tilt down 2
  * sweep
    * left  21.7
    * right 11.5
  * pitch
    * 16.8

ugh... it tilts to the right more than the left

also the body sways around a lot before settling/moving again

shiiiiiiitttt this footage is bad... I have to make it measure every degree which will slow it down.

The other thing to compensate for is that the body does not move symmetrically it starts moving backwards/to the right.

The other thing I have to update are the distance/offset per sensor

Based on the emitter location and height from the ground/distance from body center point.

For the sideways backwards lost dimensions, I will scale the SketchUp image using physical dimensions and then I can subtract the difference.

I wonder if I can mathematically figure out the offsets based on the angles above vs. watching the video/retracing stuff.

At the end of the day this stuff is not accurate at all, so many sources of error.

I think I'm going to skip ahead to the data sending part.

Basic goal is to transmit what's on the robot to the web and make sure it matches.

I'm going to do a full scan to google spreadsheet process real quick

Will help me formulate the plan to send this data

I'm tempted to send an ack back from the web interface when the data is received but idk if it's worth it.

I'm not sure what my message limit is, I'll have to test that.

Nasty flags have to set to get it to work

So I'm just looking at what I gathered.

5 sets of data: up2, up1, middle, down1, down2

up2: 3-547 rows

up1: 3-367 rows

middle: 3-547 rows

down1: 3-547 rows

down2: 3-367 rows

The ones that have less are not backtracking (no third set)

What I have to do is filter that down.

In the end what I end up using is:

5 sets of sweep angle vs. distnace (3-122, 3-82)

so let me process one tab of data and see how this goes/what data can be combined/thrown out.

I have gyro vals count, then data type eg. servo pos
don't need

These are the columns

* syncrhonizer it's time based on millis
* servo pos
* gyro sync time
* gyro vals
* depth sync time
* 

the plan will be to plot both sensor data meshes and show the accuracy

Steps to process after above

* get time in seconds
* determine elapsed time between rows (first one is same as avg)
* multiply elapsed time vs. gyro deg/s time
* accumulate the gyro time per second by adding the rows from the top down

Now both columns are determined

After this I put this data into the web mesh plotter (ThreeJS) where it is grouped by angle/sweep... and then that plots it.

It's a bit of data to chew through and then send unbroken.

I'm thinking the LED will pulse as it transmits.

I'll probably round/truncate angles in order to save data to send.

Accuracy is nice but I don't think I need a sweep angle with an accuracy of 5 decimal places. Particularly when the error is 2+ degrees per sweep side (10%+)

So yeah, I will return to this tomorrow
